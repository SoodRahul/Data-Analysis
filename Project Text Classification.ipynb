{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ecf459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a796bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets.fetch_20newsgroups()\n",
    "x=dataset.data\n",
    "y=dataset.target\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce266bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c61c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class TextClassification:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._vocab = {} # For Vocab\n",
    "        self._mainDict = None # dictionary containing Counts\n",
    "        \n",
    "    def fit(self,x_train,y_train):\n",
    "        self._buildVocab(x_train,y_train) \n",
    "        self._fitTrainingData(x_train,y_train)\n",
    "        \n",
    "    def _fitTrainingData(self,x_train,y_train):\n",
    "        for text,cls in zip(x_train,y_train):\n",
    "            text_arr = text.split()\n",
    "            text_arr = self._cleanTextArr(text_arr)\n",
    "            for txt in text_arr:\n",
    "                if txt in self._topfeat:\n",
    "                    self._mainDict[cls][txt] = self._mainDict[cls].get(txt,0) + 1            \n",
    "    \n",
    "    \n",
    "    def _buildVocab(self,x_train,y_train):\n",
    "        \n",
    "        for text in x_train:\n",
    "            text_arr = text.split()\n",
    "            text_arr = self._cleanTextArr(text_arr) # returns array of cleaned data\n",
    "            for txt in text_arr:\n",
    "                self._vocab[txt] = self._vocab.get(txt,0) + 1 # updating counts of cleaned data\n",
    "        self._topFeatures(y_train)\n",
    "            \n",
    "    def _cleanTextArr(self,text_arr:list):\n",
    "        cleaned_arr = []\n",
    "        for wrd in text_arr:\n",
    "            wrd = self._formatWord(wrd) # format word for eg: removing special character and number and email id\n",
    "            if wrd is not None:\n",
    "                cleaned_arr.append(wrd)\n",
    "        return cleaned_arr\n",
    "    \n",
    "    def _formatWord(self,wrd):\n",
    "        wrd =wrd.lower()\n",
    "        special_chr=[\".\",\":\",\">\",\"<\",\",\", \"+\", \"*\", \"?\", \"^\", \"$\", \"(\", \")\", \"[\", \"]\", \"{\", '}', \"|\",\"/\",\"-\",\"#\",'\"',\"'\",\"_\"]\n",
    "        for i in special_chr:\n",
    "            if i in wrd:\n",
    "                wrd=wrd.replace(i,\"\")\n",
    "        pattern=\"[0-9]+|@|.com\"\n",
    "        check = re.search(pattern,wrd)\n",
    "        if wrd not in ENGLISH_STOP_WORDS and check is None and len(wrd) > 2 and len(wrd) < 15:\n",
    "            return wrd\n",
    "    \n",
    "    def _topFeatures(self,y_train,percent=0.36): # return given percent of top features from vocab\n",
    "        features = self._vocab.items()\n",
    "        features = sorted(features,key=lambda x:x[1],reverse=True)\n",
    "        n=len(features)\n",
    "        index = int(percent*n)\n",
    "        Topfeatures = features[:index]\n",
    "        self._topfeat = [i for i,j in Topfeatures]\n",
    "        self._createDict(y_train)\n",
    "    \n",
    "    def _createDict(self,y_train): # creates dictionary with counts of words\n",
    "        self._classes = np.unique(y_train)\n",
    "        self._mainDict = dict.fromkeys(self._classes,{})\n",
    "        self._mainDict[\"Total_Classes\"] = len(self._classes)\n",
    "        for cls in self._classes:\n",
    "            count = len(y_train[y_train == cls])\n",
    "            self._mainDict[cls] =dict.fromkeys(self._topfeat,0)\n",
    "            self._mainDict[cls][\"Total_Count\"] =  count\n",
    "    \n",
    "    def predict(self,x_test): # returns prediction\n",
    "        y_pred = []\n",
    "        for x in x_test:\n",
    "            prediction = self._getSinglePrediction(x)\n",
    "            y_pred.append(prediction)\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def _getSinglePrediction(self,text): # return the class with highest probability \n",
    "        text_arr = text.split()\n",
    "        text_arr = self._cleanTextArr(text_arr)\n",
    "        best_prob = float('-inf')\n",
    "        best_class = None\n",
    "        for cls in self._classes:\n",
    "            prob = self._calculateProb(cls,text_arr)\n",
    "            if best_prob < prob:\n",
    "                best_prob = prob\n",
    "                best_class = cls\n",
    "        return best_class\n",
    "    \n",
    "    def _calculateProb(self,cls,text_arr:list): # calculates probability with laplace correction \n",
    "        probability = np.log(self._mainDict[cls]['Total_Count']) - np.log(self._mainDict[\"Total_Classes\"])\n",
    "        for wrd in text_arr:\n",
    "            if wrd in self._topfeat:\n",
    "                num = self._mainDict[cls][wrd] + 1\n",
    "                den = self._mainDict[cls][\"Total_Count\"] + len(self._mainDict[cls].keys())\n",
    "                \n",
    "                prob = np.log(num) - np.log(den)\n",
    "                \n",
    "                probability += prob\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed64e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TextClassification()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68699b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8602c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model is 81.27%\n"
     ]
    }
   ],
   "source": [
    "score = np.sum(y_test == y_pred) / len(y_test)\n",
    "print(f\"Accuracy of Model is {score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e19c068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       101\n",
      "           1       0.68      0.83      0.75       136\n",
      "           2       0.88      0.52      0.65       150\n",
      "           3       0.54      0.80      0.64       124\n",
      "           4       0.98      0.60      0.75       154\n",
      "           5       0.71      0.87      0.78       158\n",
      "           6       0.90      0.59      0.72       140\n",
      "           7       0.96      0.79      0.87       155\n",
      "           8       0.95      0.87      0.91       139\n",
      "           9       0.99      0.82      0.90       157\n",
      "          10       0.86      0.99      0.92       136\n",
      "          11       0.88      0.94      0.91       176\n",
      "          12       0.94      0.67      0.79       153\n",
      "          13       0.82      0.95      0.88       134\n",
      "          14       0.83      0.96      0.89       157\n",
      "          15       0.85      0.92      0.89       171\n",
      "          16       0.84      0.92      0.88       140\n",
      "          17       0.61      1.00      0.76       148\n",
      "          18       0.75      0.85      0.80       107\n",
      "          19       1.00      0.34      0.51        93\n",
      "\n",
      "    accuracy                           0.81      2829\n",
      "   macro avg       0.84      0.80      0.80      2829\n",
      "weighted avg       0.84      0.81      0.81      2829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e29b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
